{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt2 训练案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pyEnvs\\ai-quick\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 依赖的包与基础方法封装\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# 使用的设备\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# 绝对路径获取方法\n",
    "# curPath = os.path.dirname(os.path.abspath(__file__))\n",
    "# 在 jupyter 中无法获取到 __file__, 但是可以肯定的是其运行路径是文件所在目录\n",
    "curPath = os.getcwd()\n",
    "def getAbsPath (relativePath):\n",
    "  joinPath = os.path.join(curPath, relativePath)\n",
    "  return os.path.normpath(\n",
    "    os.path.abspath(joinPath)\n",
    "  )\n",
    "\n",
    "model_path = getAbsPath('../models/gpt2-chitchat-learn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的读取与数据集的制作\n",
    "这里使用编码器对需要训练的数据进行编码，并格式化为后续训练时会使用到的数据集格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9801 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9801/9801 [00:03<00:00, 2914.65it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 2992.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# 加载编码器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 读取训练需要的数据\n",
    "with open(getAbsPath('./train.txt'), 'rb') as f:\n",
    "  data = f.read().decode('utf-8')\n",
    "\n",
    "# 需要区分 linux 和 windows 环境下的换行符\n",
    "if \"\\r\\n\" in data:\n",
    "  all_data = data.split(\"\\r\\n\\r\\n\")\n",
    "else:\n",
    "  all_data = data.split(\"\\n\\n\")\n",
    "\n",
    "val_num = math.floor(len(all_data)/50)  # 1/50 的数据作为验证数据\n",
    "train_data = all_data[val_num:]\n",
    "valid_data = all_data[:val_num]\n",
    "\n",
    "# 特殊字符的编码\n",
    "sep_id = tokenizer.sep_token_id\n",
    "cls_id = tokenizer.cls_token_id\n",
    "\n",
    "# 简化该部分的代码\n",
    "# 获取对话格式化后的 input_ids\n",
    "def get_input_ids(dialogue):\n",
    "  # 将每组对话进一步拆分成一个个句子\n",
    "  if \"\\r\\n\" in data:\n",
    "    utterances = dialogue.split(\"\\r\\n\")\n",
    "  else:\n",
    "    utterances = dialogue.split(\"\\n\")\n",
    "\n",
    "  input_ids = [cls_id]        # 每个 dialogue 以 [CLS] 开头\n",
    "  for utterance in utterances:\n",
    "    input_ids += tokenizer.encode(utterance, add_special_tokens=False)\n",
    "    input_ids.append(sep_id)  # 每个句子以 [SEP] 分隔\n",
    "\n",
    "  return input_ids\n",
    "\n",
    "# 数据集格式定义\n",
    "train_data_dict = { 'text': [], 'input_ids': [] }\n",
    "valid_data_dict = { 'text': [], 'input_ids': [] }\n",
    "\n",
    "# 构建数据集\n",
    "for index, dialogue in enumerate(tqdm(train_data)):\n",
    "  input_ids = get_input_ids(dialogue)\n",
    "  train_data_dict['text'].append(dialogue)\n",
    "  train_data_dict['input_ids'].append(input_ids)\n",
    "\n",
    "for index, dialogue in enumerate(tqdm(valid_data)):\n",
    "  input_ids = get_input_ids(dialogue)\n",
    "  valid_data_dict['text'].append(dialogue)\n",
    "  valid_data_dict['input_ids'].append(input_ids)\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data_dict)\n",
    "valid_dataset = Dataset.from_dict(valid_data_dict)\n",
    "\n",
    "# 创建数据集字典并添加数据集\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = train_dataset\n",
    "dataset['valid'] = valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载与配置\n",
    "这里加载基础模型，并对需要训练的 lora 模型规格做配置，完成配置后再将两者用 peft 做拼接，并用于后续的训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pyEnvs\\ai-quick\\Lib\\site-packages\\peft\\tuners\\lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(13317, 768)\n",
       "        (wpe): Embedding(300, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-9): 10 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Linear(\n",
       "                in_features=768, out_features=2304, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=13317, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载基础模型\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# lora 模型部分的设定\n",
    "peft_config = LoraConfig(\n",
    "  task_type=TaskType.CAUSAL_LM,\n",
    "  inference_mode=True,\n",
    "  r=8,\n",
    "  lora_alpha=32,\n",
    "  lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "# lora 模型和基础模型的拼接，并在拼接完后移动到 gpu\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置对应的训练参数\n",
    "这里基于 huggingface 自定义的 Trainer 类，自定义对应的训练方法，完成对 gpt2 的 lora 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置自定义的 Trainer\n",
    "output_dir = getAbsPath('../models/gpt2-chitchat-train')\n",
    "\n",
    "# 对 Trainer 的继承与自定义\n",
    "class ModifiedTrainer(Trainer):\n",
    "  def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    return model.forward(\n",
    "      input_ids=inputs[\"input_ids\"],\n",
    "      labels=inputs[\"labels\"],\n",
    "    ).loss\n",
    "\n",
    "  def save_model(self, output_dir=None, _internal_call=None):\n",
    "    # 这里的 output_dir 是按照 epoch 或 step 做过拼接，所以可以直接使用\n",
    "    self.model.save_pretrained(output_dir)\n",
    "\n",
    "# dataloader 处理相关\n",
    "max_len = 150\n",
    "ignore_index = -100\n",
    "def data_collator(batch):\n",
    "  # 只使用数据集中的 input_ids 部分\n",
    "  batch_input_ids = [i['input_ids'] for i in batch]\n",
    "\n",
    "  # 长度截取与 tensor 化\n",
    "  format_input_ids = []\n",
    "  for idx, input_ids in enumerate(batch_input_ids):\n",
    "    input_ids = input_ids[:max_len]\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "    format_input_ids.append(input_ids)\n",
    "\n",
    "  # 使用指定的 padding_value 补齐长度不足的部分\n",
    "  input_ids = rnn_utils.pad_sequence(\n",
    "    format_input_ids, batch_first=True, padding_value=0\n",
    "  )\n",
    "  labels = rnn_utils.pad_sequence(\n",
    "    format_input_ids, batch_first=True, padding_value=ignore_index\n",
    "  )\n",
    "  return {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"labels\": labels\n",
    "  }\n",
    "\n",
    "# 训练参数配置\n",
    "# TODO 需要补充各个参数的详细含义\n",
    "output_dir = getAbsPath('../models/gpt2-chitchat-lora')\n",
    "training_args = TrainingArguments(output_dir)\n",
    "training_args.set_lr_scheduler(num_epochs=20.0, warmup_ratio=0.1)\n",
    "training_args.set_optimizer(learning_rate=2.6e-5, epsilon=1.0e-9)\n",
    "training_args.set_save(strategy='epoch')\n",
    "# training_args.set_save(steps=20)  # 采用这个在训练开始前进行快速验证\n",
    "training_args.set_training(num_epochs=20, batch_size=4, gradient_accumulation_steps=4)\n",
    "training_args.set_logging(report_to=[], strategy='steps', steps=500)\n",
    "\n",
    "# 需要简化\n",
    "# 开始训练\n",
    "trainer = ModifiedTrainer(\n",
    "  model=model,\n",
    "  train_dataset=dataset['train'],\n",
    "  data_collator=data_collator,\n",
    "  args=training_args\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-quick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
