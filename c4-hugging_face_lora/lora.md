# lora 原理机制
lora 即 `LOW-RANK` (低秩自适应)，相比于传统的继续训练中会对模型所有参数做微调，lora 采取的策略是:  
1. 冻结预训练模型的模型权重  
1. 将可训练的秩分解矩阵注入 Transformer 架构的每一层  
1. 训练过程只对上述的秩分解矩阵做训练  

在一些实践中将可训练参数的数量减少 10000 倍, GPU 内存需求减少3倍，且不损失训练质量，是后续在开源的大模型上做自定义微调的绝佳方案  

参考连接: https://zhuanlan.zhihu.com/p/611557340

## 核心论点
1. 学习的过度参数化模型实际上存在于低内在维度上(继续训练实际只调整了少量参数)  
1. 在模型自适应过程中权重的变化也具有较低的 `内在秩`  
1. LoRA允许通过优化适应过程中密集层变化的秩分解矩阵来间接训练神经网络中的一些密集层，同时保持预训练的权重不变  

结构图:  
![docs/imgs/lora.png](/c4-hugging_face_lora/lora.png)

## 关于核心论点中的一些概念
矩阵的秩:  
1. 指矩阵中矩阵中所有行向量中极大线性代无关组的元素个数  
1. 具体机制与数学意义部分可以参考: https://www.zhihu.com/question/21605094/answer/500813812  

内在秩:  
1. 在 AI 训练中，参数的表现形式一般是矩阵形式  
1. 参数的总量实际就是指矩阵的大小  
1. 依据矩阵的秩的概念可以得知，秩越大的参数矩阵理论上具有更多的表现力  
1. 而 `内在秩` 则是在在完成通用性表现力的支撑后，在奇异点(各种风格化或定制化取向)上实际涉及的 `秩`，该部分的 `秩` 实际比 `参数矩阵本身的秩` 要小很多  
1. lora 的策略就是使用 `低秩参数矩阵` 的乘积与原模型进行相加的方式来实现减少参数量  

## 矩阵公式解释
```
# 说明:
# x - 输入值(输入数据格式化后的向量)
# W0 - base model(原模型) 的参数，一个大小为 d * k 的矩阵
# △W - lora model 的参数，一个大小为 d * k 的矩阵
h = W0x + △Wx

# 说明：
# 这里所作的是降维（降秩）的实现策略
# B - 大小为 d * r 的矩阵  
# A - 大小为 r * k 的矩阵
△Wx = BAx
```

作用说明:  
1. 原本需要训练的参数量为 d * k
1. lora 机制处理后需要训练的参数量为 r * (d + k)  
1. 举例若原参数量级为 10000 * 10000 = 1B, 这里将 r 设置为 6，那么训练的参数量就变成了 6 * 20000 = 12w，极大减少了计算量（减少的计算量部分为训练时的梯度计算部分）

## 工程对应关系
在实际工程中，我们对lora策略的配置一般在 `LoraConfig` 中，案例格式如下: 
```python
peft_config = LoraConfig(
  task_type=TaskType.CAUSAL_LM,
  inference_mode=False,
  r=8,
  lora_alpha=32,
  lora_dropout=0.1,
  target_modules=["query_key_value"]
)
```

说明：  
1. 参数 r: 对应的关系就是上述的矩阵计算公式中的 r  
1. lora_alpha: lora_alpha/r 即为上述 △W 的归一化系数  
1. lora_dropout: 控制 lora 模型部分在训练时的随机丢弃率，即 forward 过程中每个神经元的输出都以一定的概率被置为0，这样可以使得模型在训练过程中不能过分依赖某些特定的神经元，该值越大模型就越泛化(也有欠拟合的风险)，越小则模型也就越不泛化(有过拟合风险)，需要取合适的值  

## 关键的 benchmark
在超过一定值后，参数 r 的增加对训练结果的改善没有具体提升，原因分析如下:  
1. 特定方向的业务的特殊性其 `内在秩` 实际较为固定，其所反应的是该方向业务的复杂度或是其依赖的表现力  
1. 参数 r 表示的是所调整适配的目标的实际依赖的表现力（复杂度）  
1. 当参数 r 超过对应业务的 `内在秩` 时，即使其 `矩阵秩` 较大，而其 `内在秩` 却是对应事务的特殊性的复杂度阈值，是一个不会随着 `矩阵秩` 变大的值  

## 一些补充理解
1. base model 的参数量决定了模型整体支持的任务复杂度以及表现力  
1. 虽然针对具体业务 lora 训练只调整了部分参数，但并不是表明这类业务只需要这少量的参数就足以支撑其复杂度与表现力  
1. 而是因为有 base model 作为底层的复杂度与表现力支撑的前提下，只用作少量微调就能支撑特定的业务  
1. 要做一个类比的话，就是经验丰富的程序员在学习一门新的编程语言时，只需要做少量的工作（其历史经验就是 base model，而 lora 部分就是学新语言时的少量适配学习）

