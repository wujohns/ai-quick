# gpt2 模型训练相关
本章节主要以 gpt2 模型的 lora 训练为引子，展开说明以下的知识点:  
1. lora 的原理  
1. peft 框架  
1. 模型训练要点  
1. 模型训练工程实践  

## lora 原理介绍
参考 [c4-hugging_face_lora/lora.png](/c4-hugging_face_lora/lora.png)  

## peft 框架说明
peft 作为 huggingface 的生态的一部分:  
1. 其主要侧重的方向是模型快速微调  
1. 集成了对多种主流模型的不同微调方案(例如本章节中对 gpt2 的 lora 微调方案)  
1. 其加速模型微调的核心之处在于降低训练模型时的需要求导的参数量  

官方文档: https://huggingface.co/docs/peft/index  
工程repo: https://github.com/huggingface/peft  

## 模型训练要点梳理
回顾课程 c2 章节中的模型训练图解:  
![train_bostan_struc.png](/c2-autograd_and_baseex/train_bostan_struc.png)  

结合这个图解我们会发现模型的训练有以下的要点:  
1. loss 计算 - 以何种方式以及什么样的 loss 函数计算  
1. 模型参数调整速度 - 即学习率，在实际生产中会有较为细化的策略，例如调整速度逐渐增大到最大值，学习率的具体数值(每次变化的幅度系数)，以及避免梯度计算中为了避免 0 作为分母而设定最小常数  
1. 训练轮次、每一步训练读取的数据量  

以及一个会随着模型设计策略变动的要点:  
1. 训练数据的 格式化/对齐  

细化后图解如下:  
![struc.png](/c4-hugging_face_lora/struc.png)  

## Trianer 使用说明
Trainer 属于 huggingface 生态中的 transformers 包部分，其主要点:  
1. 将常用的训练流程进行了封装，便于模型训练实现的编写  
1. 训练的 过程/结果 也能很好的和 huggingface 生态结合，便于社区的交流  

一般来说我们直接继承 Trainer 并:  
1. 定制化其 compute_loss 方法 - Trainer 默认的 compute_loss 大概率与我们期望的 loss 计算不同，需要以及具体的模型实现做修改  
1. 定制化其 save_model 方法 - 主要训练后模型的保存路径  

## 使用训练好的 lora 进行运行
参考 [c4-hugging_face_lora/gpt2-run.ipynb](/c4-hugging_face_lora/gpt2-run.ipynb)  
修改其中载入的 lora 模型的路径为自己训练出来的 lora 模型路径即可:  
```py
...
model = PeftModel.from_pretrained(
  model,
  getAbsPath('../models/gpt2-chitchat-lora/checkpoint-20')
)
...
```
